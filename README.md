# CryptoStream ETL Pipeline

A Python-based ETL (Extract, Transform, Load) pipeline that fetches cryptocurrency market data from the CoinGecko API, processes it, and loads it into a PostgreSQL database. The pipeline is automated using Windows Task Scheduler.

---

## ğŸš€ Overview

This project demonstrates a real-world data engineering workflow:
- API data ingestion
- Data cleaning and transformation
- Database loading with UPSERT logic
- Automation on Windows
- Environment variable management
- GitHub-ready structure

---

## ğŸ—ï¸ Architecture Diagram

<img src="Assets/ETL.png" width="700">



---

## ğŸ“‚ Project Structure

CryptoStream_Pipeline/
â”‚â”€â”€ extract.py # Extract data from CoinGecko API
â”‚â”€â”€ transform.py # Transform and clean data
â”‚â”€â”€ load.py # Load data into PostgreSQL
â”‚â”€â”€ main.py # Orchestrates ETL steps
â”‚â”€â”€ run_pipeline.bat # Automation via Task Scheduler
â”‚â”€â”€ .env # Environment variables (ignored by git)
â”‚â”€â”€ README.md # Project documentation
â”‚â”€â”€ etl_log.txt # Execution logs

yaml
Copy code

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/CryptoStream_Pipeline.git
cd CryptoStream_Pipeline
2ï¸âƒ£ Create and activate virtual environment
bash
Copy code
python -m venv venv
venv\Scripts\activate
Install dependencies:

bash
Copy code
pip install pandas requests python-dotenv psycopg2
3ï¸âƒ£ Create .env file
env
Copy code
COINGECKO_API_KEY=your_api_key
DB_HOST=localhost
DB_PORT=5432
DB_NAME=crypto_db
DB_USER=postgres
DB_PASSWORD="your_password"
.env is excluded from GitHub for security.

4ï¸âƒ£ Create PostgreSQL table
sql
Copy code
CREATE TABLE IF NOT EXISTS coins_market (
    id TEXT PRIMARY KEY,
    symbol TEXT,
    name TEXT,
    current_price NUMERIC,
    market_cap NUMERIC,
    market_cap_rank INTEGER,
    total_volume NUMERIC,
    high_24h NUMERIC,
    low_24h NUMERIC,
    price_change_percentage_24h NUMERIC,
    last_updated TIMESTAMP
);
â–¶ï¸ Running the Pipeline
Manual run
bash
Copy code
python main.py
Automated (Windows)
Double-click run_pipeline.bat

Or schedule it using Windows Task Scheduler

Execution logs are stored in etl_log.txt.